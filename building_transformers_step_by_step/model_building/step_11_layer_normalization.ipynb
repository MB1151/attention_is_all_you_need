{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, you learn:\n",
    "#\n",
    "# 1) What is Layer Normalization?\n",
    "# 2) How to use Layer Normalization in Transformers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources to go through before continuing further in this notebook:\n",
    "#\n",
    "# 1) https://www.youtube.com/watch?v=tNIpEZLv_eg\n",
    "#       -- This video explains the concept of Batch Normalization in a very simple way.\n",
    "#       -- It is useful to understand Batch Normalization before understanding Layer Normalization.\n",
    "# 2) https://www.youtube.com/watch?v=em6dfRxYkYU\n",
    "#       -- This video gives intuition on why Batch Normalization works.\n",
    "# 3) https://www.kaggle.com/code/halflingwizard/how-does-layer-normalization-work\n",
    "#       -- This blog explains the concept of Layer Normalization.\n",
    "# 4) https://www.youtube.com/watch?v=2V3Uduw1zwQ&t=103s\n",
    "#       -- This video runs Layer Normalization on a simple example and explains the results.\n",
    "# 5) https://leimao.github.io/blog/Layer-Normalization/\n",
    "#       -- Explains the mathematics behind Layer Normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [torch.LayerNorm](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([4, 5])\n",
      "t1:  tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.,  9.],\n",
      "        [10., 11., 12., 13., 14.],\n",
      "        [15., 16., 17., 18., 19.]])\n"
     ]
    }
   ],
   "source": [
    "# t1 contains 4 inputs and 5 features.\n",
    "# Each row represents an input and each column represents a feature.\n",
    "t1 = torch.arange(start=0, end=20, step=1, dtype=torch.float32).reshape(4, 5)\n",
    "print(\"shape: \", t1.shape)\n",
    "print(\"t1: \", t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_norm:  LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "shape of gamma or weights:  torch.Size([5])\n",
      "gamma or weights:  Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "shape of beta or bias:  torch.Size([5])\n",
      "beta or bias:  Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Layer Normalization is applied on the features of the each input independently. It takes each\n",
    "# row (corresponding to a single input), calculates the mean and standard deviation of the features\n",
    "# of that input, and normalizes the features of that input using the mean and standard deviation.\n",
    "# The formula for Layer Normalization is:\n",
    "# Layer Normalization = (gamma * (x - mean) / sqrt(variance + epsilon)) + beta\n",
    "# \n",
    "# where: x is the input, gamma and beta are learnable parameters, mean and variance are the mean and\n",
    "# variance of the features of the input, and epsilon is a small number to avoid division by zero.\n",
    "\n",
    "# normalized_shape corresponds to the number of features.\n",
    "layer_norm_1 = nn.LayerNorm(normalized_shape=5)\n",
    "print(\"layer_norm: \", layer_norm_1)\n",
    "print(\"-\" * 150)\n",
    "# Note the size of the weights and bias. The size of the weights is equal to the number of features.\n",
    "# Each feature has a gamma and a beta exclusively associated with it i.e., the model learns optimal \n",
    "# scaling and shifting factors for each feature separately.\n",
    "print(\"shape of gamma or weights: \", layer_norm_1.weight.shape)\n",
    "print(\"gamma or weights: \", layer_norm_1.weight)\n",
    "print(\"-\" * 150)\n",
    "print(\"shape of beta or bias: \", layer_norm_1.bias.shape)\n",
    "print(\"beta or bias: \", layer_norm_1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([4, 5])\n",
      "normalized_input:  tensor([[-1.4142, -0.7071,  0.0000,  0.7071,  1.4142],\n",
      "        [-1.4142, -0.7071,  0.0000,  0.7071,  1.4142],\n",
      "        [-1.4142, -0.7071,  0.0000,  0.7071,  1.4142],\n",
      "        [-1.4142, -0.7071,  0.0000,  0.7071,  1.4142]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Lets take the first input and apply Layer Normalization on it and verify the results with manual calculation.\n",
    "# The first input is: [0, 1, 2, 3, 4]\n",
    "# The mean of the features of the first input is: (0 + 1 + 2 + 3 + 4) / 5 = 2\n",
    "# The standard deviation of the features of the first input is: sqrt(((0 - 2)^2 + (1 - 2)^2 + (2 - 2)^2 + (3 - 2)^2 + (4 - 2)^2) / 5) = sqrt(2)\n",
    "# The normalized features of the first input are: [(0 - 2) / sqrt(2), (1 - 2) / sqrt(2), (2 - 2) / sqrt(2), (3 - 2) / sqrt(2), (4 - 2) / sqrt(2)]\n",
    "# The normalized features of the first input are: [-1.41, -0.71, 0, 0.71, 1.41]\n",
    "t1_normalized_1 = layer_norm_1(t1)\n",
    "print(\"shape: \", t1_normalized_1.shape)\n",
    "print(\"normalized_input: \", t1_normalized_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2, 3, 4])\n",
      "t2:  tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.]],\n",
      "\n",
      "        [[12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19.],\n",
      "         [20., 21., 22., 23.]]])\n"
     ]
    }
   ],
   "source": [
    "# Layer normalization acts on the elements of the last dimension of the input tensor (shape doesn't matter).\n",
    "# Now, lets try and see what Layer Normalization does to a 3D tensor. \n",
    "t2 = torch.arange(start=0, end=24, step=1, dtype=torch.float32).reshape(2, 3, 4)\n",
    "print(\"shape: \", t2.shape)\n",
    "print(\"t2: \", t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_norm:  LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "shape of gamma or weights:  torch.Size([4])\n",
      "gamma or weights:  Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "shape of beta or bias:  torch.Size([4])\n",
      "beta or bias:  Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "shape:  torch.Size([2, 3, 4])\n",
      "t2_normalized_1:  tensor([[[-1.3416, -0.4472,  0.4472,  1.3416],\n",
      "         [-1.3416, -0.4472,  0.4472,  1.3416],\n",
      "         [-1.3416, -0.4472,  0.4472,  1.3416]],\n",
      "\n",
      "        [[-1.3416, -0.4472,  0.4472,  1.3416],\n",
      "         [-1.3416, -0.4472,  0.4472,  1.3416],\n",
      "         [-1.3416, -0.4472,  0.4472,  1.3416]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer_norm_2_1 = nn.LayerNorm(normalized_shape=4)\n",
    "print(\"layer_norm: \", layer_norm_2_1)\n",
    "print(\"-\" * 150)\n",
    "print(\"shape of gamma or weights: \", layer_norm_2_1.weight.shape)\n",
    "print(\"gamma or weights: \", layer_norm_2_1.weight)\n",
    "print(\"-\" * 150)\n",
    "print(\"shape of beta or bias: \", layer_norm_2_1.bias.shape)\n",
    "print(\"beta or bias: \", layer_norm_2_1.bias)\n",
    "print(\"-\" * 150)\n",
    "# This is the same as above shown for t1. We have normalized across the last dimension.\n",
    "t2_normalized_1 = layer_norm_2_1(t2)\n",
    "print(\"shape: \", t2_normalized_1.shape)\n",
    "print(\"t2_normalized_1: \", t2_normalized_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_norm:  LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given normalized_shape=[3], expected input with shape [*, 3], but got input of size[2, 3, 4]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_norm: \u001b[39m\u001b[38;5;124m\"\u001b[39m, layer_norm_2_error)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# This raises error as expected. By default, Layer Norm tries to normalize across the last dimension.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# The normalized_shape passed to LayerNorm should be the size of the last dimension of the input tensor.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# If the expected shape (normalized_shape or number of features) doesn't match the last dimension of \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# the input tensor, then it raises an error.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m t2_normalized_error \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_norm_2_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/lib/python3.10/site-packages/torch/nn/modules/normalization.py:201\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/lib/python3.10/site-packages/torch/nn/functional.py:2573\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2571\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m   2572\u001b[0m     )\n\u001b[0;32m-> 2573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given normalized_shape=[3], expected input with shape [*, 3], but got input of size[2, 3, 4]"
     ]
    }
   ],
   "source": [
    "layer_norm_2_error = nn.LayerNorm(normalized_shape=3)\n",
    "print(\"layer_norm: \", layer_norm_2_error)\n",
    "# This raises error as expected. By default, Layer Norm tries to normalize across the last dimension.\n",
    "# The normalized_shape passed to LayerNorm should be the size of the last dimension of the input tensor.\n",
    "# If the expected shape (normalized_shape or number of features) doesn't match the last dimension of \n",
    "# the input tensor, then it raises an error.\n",
    "t2_normalized_error = layer_norm_2_error(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_norm_2_2:  LayerNorm((3, 4), eps=1e-05, elementwise_affine=True)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "shape of gamma or weights:  torch.Size([3, 4])\n",
      "gamma or weights:  Parameter containing:\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], requires_grad=True)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "shape of beta or bias:  torch.Size([3, 4])\n",
      "beta or bias:  Parameter containing:\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], requires_grad=True)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "shape:  torch.Size([2, 3, 4])\n",
      "t2_normalized_2:  tensor([[[-1.5933, -1.3036, -1.0139, -0.7242],\n",
      "         [-0.4345, -0.1448,  0.1448,  0.4345],\n",
      "         [ 0.7242,  1.0139,  1.3036,  1.5933]],\n",
      "\n",
      "        [[-1.5933, -1.3036, -1.0139, -0.7242],\n",
      "         [-0.4345, -0.1448,  0.1448,  0.4345],\n",
      "         [ 0.7242,  1.0139,  1.3036,  1.5933]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Now, lets try to understand what does it mean to apply Layer Normalization across multiple dimensions. For now, \n",
    "# consider we have some random input tensor and we want to apply Layer Normalization to the input. \n",
    "# Here, by default, LayerNorm normalizes across the \"last\" 2 dimensions since the 'normalized_shape' has shape 2 (2 dimensions).\n",
    "layer_norm_2_2 = nn.LayerNorm(normalized_shape=[3, 4])\n",
    "print(\"layer_norm_2_2: \", layer_norm_2_2)\n",
    "print(\"-\" * 150)\n",
    "# Note the size of the weights and bias. The size of the weights is equal to the number of features or \n",
    "# normalized_shape. Each feature has a gamma and a beta associated with it i.e., the model learns optimal \n",
    "# scaling and shifting factors for each feature separately.\n",
    "print(\"shape of gamma or weights: \", layer_norm_2_2.weight.shape)\n",
    "print(\"gamma or weights: \", layer_norm_2_2.weight)\n",
    "print(\"-\" * 150)\n",
    "print(\"shape of beta or bias: \", layer_norm_2_2.bias.shape)\n",
    "print(\"beta or bias: \", layer_norm_2_2.bias)\n",
    "print(\"-\" * 150)\n",
    "# We obtain groups of 2D tensors since we consider the last 2 dimensions. For each group, mean and variance are calculated\n",
    "# independently which are then used to normalize the values within that group. So, each element is only present in\n",
    "# 1 group and normalized by only one set of mean and variance.\n",
    "# For example: in t2, \n",
    "# the first group is [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]] and \n",
    "# the second group is [[12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23]]. \n",
    "#\n",
    "# Now, consideing the first group, the mean is (0 + 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10 + 11) / 12 = 5.5 and \n",
    "# the variance is sqrt(((0 - 5.5)^2 + (1 - 5.5)^2 + (2 - 5.5)^2 + (3 - 5.5)^2 + (4 - 5.5)^2 + (5 - 5.5)^2 + (6 - 5.5)^2 + (7 - 5.5)^2 + (8 - 5.5)^2 + (9 - 5.5)^2 + (10 - 5.5)^2 + (11 - 5.5)^2) / 12) = 3.45\n",
    "# \n",
    "# The normalized features of the first group are (ignoring the eplison and gamma and beta for now):\n",
    "# [[(0 - 5.5) / 3.45, (1 - 5.5) / 3.45, (2 - 5.5) / 3.45, (3 - 5.5) / 3.45, (4 - 5.5) / 3.45, (5 - 5.5) / 3.45, (6 - 5.5) / 3.45, (7 - 5.5) / 3.45, (8 - 5.5) / 3.45, (9 - 5.5) / 3.45, (10 - 5.5) / 3.45, (11 - 5.5) / 3.45]]\n",
    "t2_normalized_2 = layer_norm_2_2(t2)\n",
    "print(\"shape: \", t2_normalized_2.shape)\n",
    "print(\"t2_normalized_2: \", t2_normalized_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly if the normalized_shape is of size 3, then the normalization is done across the last 3 dimensions.\n",
    "# This is similar to applying LayerNorm on the last 2 dimensions as shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Normalization In Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer Normalization in transformers is used the same way as shown above. The only difference is that the\n",
    "# input to the LayerNorm is the output of the Multi-Head Attention or Feed Forward Neural Network. So, the\n",
    "# input is a 3D tensor and LayerNorm is applied on the last dimension. The normalized_shape is the size of\n",
    "# the last dimension of the input tensor.\n",
    "#\n",
    "# Although the 'Annotated Transformer' uses its own implementation to apply LayerNorm, we will be using the\n",
    "# PyTorch's implementation of LayerNorm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "sequence_length = 4\n",
    "d_model = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([3, 4, 5])\n",
      "transformer_input:  tensor([[[ 0.,  1.,  2.,  3.,  4.],\n",
      "         [ 5.,  6.,  7.,  8.,  9.],\n",
      "         [10., 11., 12., 13., 14.],\n",
      "         [15., 16., 17., 18., 19.]],\n",
      "\n",
      "        [[20., 21., 22., 23., 24.],\n",
      "         [25., 26., 27., 28., 29.],\n",
      "         [30., 31., 32., 33., 34.],\n",
      "         [35., 36., 37., 38., 39.]],\n",
      "\n",
      "        [[40., 41., 42., 43., 44.],\n",
      "         [45., 46., 47., 48., 49.],\n",
      "         [50., 51., 52., 53., 54.],\n",
      "         [55., 56., 57., 58., 59.]]])\n"
     ]
    }
   ],
   "source": [
    "transformer_input = torch.arange(start=0, end=batch_size * sequence_length * d_model, step=1, dtype=torch.float32).reshape(batch_size, sequence_length, d_model)\n",
    "print(\"shape: \", transformer_input.shape)\n",
    "print(\"transformer_input: \", transformer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer_layer_norm:  LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "weights:  Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n",
      "bias:  Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "transformer_layer_norm = nn.LayerNorm(normalized_shape=d_model)\n",
    "print(\"transformer_layer_norm: \", transformer_layer_norm)\n",
    "print(\"weights: \", transformer_layer_norm.weight)\n",
    "print(\"bias: \", transformer_layer_norm.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([3, 4, 5])\n",
      "normalized_input:  tensor([[[-1.4142, -0.7071,  0.0000,  0.7071,  1.4142],\n",
      "         [-1.4142, -0.7071,  0.0000,  0.7071,  1.4142],\n",
      "         [-1.4142, -0.7071,  0.0000,  0.7071,  1.4142],\n",
      "         [-1.4142, -0.7071,  0.0000,  0.7071,  1.4142]],\n",
      "\n",
      "        [[-1.4142, -0.7071,  0.0000,  0.7071,  1.4142],\n",
      "         [-1.4142, -0.7071,  0.0000,  0.7071,  1.4142],\n",
      "         [-1.4142, -0.7071,  0.0000,  0.7071,  1.4142],\n",
      "         [-1.4142, -0.7071,  0.0000,  0.7071,  1.4142]],\n",
      "\n",
      "        [[-1.4142, -0.7071,  0.0000,  0.7071,  1.4142],\n",
      "         [-1.4142, -0.7071,  0.0000,  0.7071,  1.4142],\n",
      "         [-1.4142, -0.7071,  0.0000,  0.7071,  1.4142],\n",
      "         [-1.4142, -0.7071,  0.0000,  0.7071,  1.4142]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "normalized_output = transformer_layer_norm(transformer_input)\n",
    "print(\"shape: \", normalized_output.shape)\n",
    "print(\"normalized_input: \", normalized_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".attention_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
