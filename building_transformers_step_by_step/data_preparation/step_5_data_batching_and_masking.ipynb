{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, you learn:\n",
    "#\n",
    "# 1) How to create Batch objects out of the batched data from dataloaders and use it for training?\n",
    "# 2) How is masking used in Transformers and how to create these masks for source and target sentences?\n",
    "#\n",
    "# NOTE: It might be a good idea to ignore the masking part (this notebook) for now. It might be easier if you go ahead \n",
    "# and understand how to implement the MultiHeadAttention, Encoder Layer and Decoder layer without masking and then \n",
    "# come back to this notebook to understand masking i.e., probably come back to this after you understand everything \n",
    "# until 'step_13_decoder.ipynb'. The shapes here can get a bit confusing and it might be easier to understand them \n",
    "# after you have implemented the MultiHeadAttention, Encoder and Decoder without masking. If you are already familiar \n",
    "# with MultiHeadAttention, then you can continue with this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful respources:\n",
    "# \n",
    "# 1) https://nlp.seas.harvard.edu/annotated-transformer/#batches-and-masking\n",
    "#       -- The Annotated Transformer by Harvard NLP. It uses a specific format to hold batches and masks. I use the same\n",
    "#          format in this notebook and explain each part of it.\n",
    "# 2) https://jalammar.github.io/illustrated-transformer/\n",
    "#       -- Illustrated Transformer by Jay Alammar.\n",
    "# 3) https://www.youtube.com/watch?v=IGu7ivuy1Ag\n",
    "#       -- Explains how the source and target sentences are used by the Encoder and Decoder.\n",
    "#       -- Useful to understand the logic in target sentence creating within the Batch object below.\n",
    "# 4) https://www.garysnotebook.com/20210128_1\n",
    "#       -- Explains how masking is done. Does not explain everything and leaves out some important details.\n",
    "# 5) https://stats.stackexchange.com/questions/598239/how-is-padding-masking-considered-in-the-attention-head-of-a-transformer\n",
    "#       -- Discussed about how to use padding mask in target sentences.\n",
    "#       -- This was the exact confusion I had and I also don't see the need for padding mask in target sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The decoder takes a batch of sequences as input and returns a batch of sequences as output. Every sequence in the \n",
    "# batch is of same length. The length of the sequence is the number of tokens in it (just for our purposes here). \n",
    "# In the decoder, the 'mask' is used to prevent the tokens appearing after the current token to attend to the \n",
    "# current token or any token before it i.e., we do not want the model to look at the future tokens when predicting \n",
    "# the current token in the translation task. This is done because during inference, the model will not have access \n",
    "# to the future tokens. \n",
    "#\n",
    "# The mask is applied when the normalized weights are calculated for the attention mechanism. By applying the mask, \n",
    "# the weights of the future tokens are set to zero --> Please follow the 'step_9_multi_headed_attention.ipynb' \n",
    "# notebook to exactly understand how the mask is applied. For now, if we ignore the batch dimension, the mask is a \n",
    "# square matrix of size (seq_len, seq_len) where seq_len is the length of the sequence. The mask is a lower triangular \n",
    "# matrix where the elements above the diagonal are set to False and the elements below the diagonal are set to True. \n",
    "# This is because we want to prevent the tokens appearing after the current token to attend to the current token or \n",
    "# any token before it. The tokens set to False in a particular row do not attend the token represented by that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples constants to experiment with batches and masks.\n",
    "# Sentence length in a batch. This varies from batch to batch.\n",
    "seq_len = 10\n",
    "# Id of the token that marks the beginning of a sentence.\n",
    "sos_token_id = 0\n",
    "# Id of the token that marks the end of a sentence.\n",
    "eos_token_id = 1\n",
    "# Id of Padding token. This is used to pad the sentences in a batch to make them of same length.\n",
    "pad_token_id = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Look Ahead Mask --> Only for target sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([10, 10])\n",
      "up_triangular_matrix: \n",
      " tensor([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.uint8)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "shape:  torch.Size([10, 10])\n",
      "attention_mask: \n",
      " tensor([[ True, False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "# Notice that all the elements on the main diagonal and below it are set to zero in the up_traingular_matrix tensor.\n",
    "# Refer to 'understanding_tensor_manipulations_part_7.ipynb' notebook to understand more about the 'torch.triu' \n",
    "# function.\n",
    "up_triangular_matrix = torch.triu(torch.ones(seq_len, seq_len, dtype=torch.uint8), diagonal=1)\n",
    "print(\"shape: \", up_triangular_matrix.shape)\n",
    "print(\"up_triangular_matrix: \\n\", up_triangular_matrix)\n",
    "print(\"-\" * 150)\n",
    "\n",
    "# The attention mask can be understood by tagging tokens to rows and columns as shown below.\n",
    "#\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "#              | tok 0 | tok 1 | tok 2 | . . . | tok (n - 1)\n",
    "#              |------------------------------------------------\n",
    "# tok 0        |       |       |       |       |\n",
    "# tok 1        |       |       |       |       |\n",
    "# tok 2        |       |       |       |       |\n",
    "# .            |       |       |       |       |\n",
    "# .            |       |       |       |       |\n",
    "# .            |       |       |       |       |\n",
    "# tok (n - 1)  |       |       |       |       |\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "#\n",
    "# elements in row 'i' tell what all tokens can attend to token in 'i' in the attention score calculation.\n",
    "#\n",
    "# attention_mask[0][0] = True --> This means that the first token can attend to itself.\n",
    "# attention_mask[0][1] = False --> This means that the second token cannot attend to the first token.\n",
    "#\n",
    "# In general, \n",
    "# attention_mask[i][j] = True --> This means that the jth token can attend to the ith token.\n",
    "# attention_mask[i][j] = False --> This means that the jth token cannot attend to the ith token.\n",
    "# Only the weights where mask is True are used in the attention scores calculation.\n",
    "#\n",
    "# Lets consider the first token (row 1). Only the first token can attend to itself. The tokens after first token \n",
    "# cannot attend to the first token. Hence, in the first row, only the first element is True and the rest are False. \n",
    "# The same applies to the second token. The second token can attend to the first token and itself. The tokens \n",
    "# after the second token cannot attend to the second token. Hence, the second row has two True elements in the \n",
    "# first two indices and the rest are False. This pattern continues for all the tokens in the sentence.\n",
    "attention_mask = (up_triangular_matrix == 0)\n",
    "print(\"shape: \", attention_mask.shape)\n",
    "print(\"attention_mask: \\n\", attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is just created by combining the code from the above cells into a single function.\n",
    "# This function will be used later when creating the mask in the Batch object.\n",
    "def construct_look_ahead_mask(size: int) -> Tensor:\n",
    "    \"\"\"Create a mask to prevent the tokens appearing after the current token \n",
    "       to attend to the current token or any token before it.\n",
    "\n",
    "    Args:\n",
    "        size (int): Size of the mask to be created i.e., the length of the sentence.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: A boolean tensor of shape (size, size).\n",
    "    \"\"\"\n",
    "    attention_mask = torch.triu(torch.ones(size, size, dtype=torch.uint8), diagonal=1)\n",
    "    return attention_mask == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([10, 10])\n",
      "look_ahead_mask: \n",
      " tensor([[ True, False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "look_ahead_mask = construct_look_ahead_mask(seq_len)\n",
    "print(\"shape: \", look_ahead_mask.shape)\n",
    "print(\"look_ahead_mask: \\n\", look_ahead_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Padding Mask --> Both for source and target sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, lets ignore the target sentences and focus on the source sentences.\n",
    "# When creating the mask for the source sequences, we need to create a mask that prevents the padding tokens from \n",
    "# attending to the actual text tokens. The padding tokens are the tokens that are added to the sequences that are \n",
    "# shorter than the longest sequence in the batch. The padding tokens are added to the end of the sequence. The \n",
    "# mask is created by checking the indices of the padding tokens and setting the corresponding indices in the mask \n",
    "# to False.\n",
    "#\n",
    "# Here, we are not bothered about the future tokens attending to the current token. This is because the source\n",
    "# sequences are the input to the Encoder and the Encoder does not have to predict the next token. The encoder \n",
    "# only has to encode the input sequences. Hence, we do not need to prevent the future tokens from attending to \n",
    "# the current token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2, 10])\n",
      "src_batch: \n",
      " tensor([[   24,    42,    33,  4124,   231, 12321,     2,     2,     2,     2],\n",
      "        [   27,    67,    83, 23124,   131,  1321,    23,    90,     2,     2]])\n"
     ]
    }
   ],
   "source": [
    "# src_sequence is of the format [token_1 token_2 ... token_n <pad> <pad> ... <pad>]\n",
    "# where <pad> is the padding token. Notice that src_sequence does not have the '<sos>' and '<eos>' tokens. They\n",
    "# are only present in the target_sequence and do not serve any purpose in the source_sequence.\n",
    "src_batch = torch.tensor(data=[[24, 42, 33, 4124, 231, 12321, pad_token_id, pad_token_id, pad_token_id, pad_token_id], \n",
    "                               [27, 67, 83, 23124, 131, 1321, 23, 90, pad_token_id, pad_token_id]], dtype=torch.int64)\n",
    "print(\"shape: \", src_batch.shape)\n",
    "print(\"src_batch: \\n\", src_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2, 10])\n",
      "src_mask: \n",
      " tensor([[ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True, False, False]])\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "shape:  torch.Size([2, 1, 10])\n",
      "src_mask: \n",
      " tensor([[[ True,  True,  True,  True,  True,  True, False, False, False, False]],\n",
      "\n",
      "        [[ True,  True,  True,  True,  True,  True,  True,  True, False, False]]])\n"
     ]
    }
   ],
   "source": [
    "src_mask = (src_batch != pad_token_id)\n",
    "print(\"shape: \", src_mask.shape)\n",
    "print(\"src_mask: \\n\", src_mask)\n",
    "print(\"-\" * 150)\n",
    "# We add a dimension so that the mask can be broadcasted with the batched data when used in transformers. src_mask tensor \n",
    "# above contains 1 row per sequence in the batch. The mask need to contain one row per token which contains the \n",
    "# information about what other tokens can attend to the token in the current row. Since, we are calculating the padding \n",
    "# mask, the mask is same for every single token in one sequence. However, we will not explicitly create the mask for every \n",
    "# token in the sequence. We will just create 1 row and allow python's broadcasting to take care of the rest of the rows \n",
    "# in the sequence when the mask is used in the transformer. \n",
    "# On an additional note, it might be tempting to make the src_mask of shape [batch_size, seq_len, seq_len] instead of \n",
    "# leaving it as [batsh_size, 1, seq_len]. However, for the src_mask to be used with self attention in Encoder, the shape \n",
    "# should be [batch_size, seq_len, seq_len] and for the src_mask to be used with source attention in Decoder, the shape \n",
    "# should be [batch_size, seq_len - 1, seq_len]. So, we will keep the shape of src_mask as [batch_size, 1, seq_len] and \n",
    "# then let the model handle the broadcasting of the mask to the required shape. Please note that we have omitted the \n",
    "# dimension that corresponds to the number of heads in the mask to keep things simple for now. Lets handle this below.\n",
    "src_mask = src_mask.unsqueeze(1)\n",
    "print(\"shape: \", src_mask.shape)\n",
    "print(\"src_mask: \\n\", src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is just created by combining the code from the above cells into a single function.\n",
    "def construct_padding_mask(input: Tensor, pad_token_id: int) -> Tensor:\n",
    "    \"\"\"Create a mask to prevent the padding tokens from attending to the tokens.\n",
    "\n",
    "    Args:\n",
    "        input (Tensor): A batch of sentences of shape (batch_size, seq_len).\n",
    "        pad_token_id (int): Id of the padding token.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: A boolean tensor of shape (batch_size, seq_len, seq_len).\n",
    "    \"\"\"\n",
    "    mask = (input != pad_token_id)\n",
    "    mask = mask.unsqueeze(1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2, 1, 10])\n",
      "src_mask_via_function: \n",
      " tensor([[[ True,  True,  True,  True,  True,  True, False, False, False, False]],\n",
      "\n",
      "        [[ True,  True,  True,  True,  True,  True,  True,  True, False, False]]])\n"
     ]
    }
   ],
   "source": [
    "src_mask_via_function = construct_padding_mask(input=src_batch, pad_token_id=pad_token_id)\n",
    "print(\"shape: \", src_mask_via_function.shape)\n",
    "print(\"src_mask_via_function: \\n\", src_mask_via_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both the source masks are equal as they should be.\n"
     ]
    }
   ],
   "source": [
    "if torch.equal(src_mask, src_mask_via_function):\n",
    "    print(\"Both the source masks are equal as they should be.\")\n",
    "else:\n",
    "    print(\"The source masks are not equal. There is some mistake in the code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2, 1, 1, 10])\n",
      "src_mask: \n",
      " tensor([[[[ True,  True,  True,  True,  True,  True, False, False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True,  True,  True,  True,  True,  True, False, False]]]])\n"
     ]
    }
   ],
   "source": [
    "# In the transformers implementation, the same mask is applied to all the heads in the multi-headed attention mechanism. \n",
    "# The calculated attention_scores will have the shape [batch_size, num_heads, seq_len, seq_len] in self attention. \n",
    "# Hence, the src_mask is updated to have the shape [batch_size, 1, 1, seq_len] which can be broadcasted and applied to \n",
    "# all the heads.\n",
    "src_mask = src_mask.unsqueeze(1)\n",
    "print(\"shape: \", src_mask.shape)\n",
    "print(\"src_mask: \\n\", src_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More About Target Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target sequence is of the format [<sos> token_1 token_2 ... token_n <eos> <pad> <pad> ... <pad>] where <sos> \n",
    "# is the start of sequence token, <eos> is the end of sequence token and <pad> is the padding token.\n",
    "# \n",
    "# target sequence is used in two ways in the Decoder during training. The target sequence is used as an input\n",
    "# to the decoder to predict the next token in the output target sequence. The target sequence is also used to \n",
    "# calculate the loss. The target sequence is shifted by one position to the left when used to calculate the loss. \n",
    "# This is because the model should predict the next token in the target sequence and not the current token.\n",
    "#\n",
    "# target = [<sos> token_1 token_2 ... token_n <eos> <pad> <pad> ... <pad>]\n",
    "#       -- The target sequence from the data loader.\n",
    "#       -- Length: L\n",
    "# target_decoder_input = [<sos> token_1 token_2 ... token_n <eos> <pad> <pad> ... <pad>]\n",
    "#       -- The last token (<pad> for this example) from the target is removed to create the target_decoder_input.\n",
    "#       -- Length: (L - 1)\n",
    "# target_expected_decoder_output = [token_1 token_2 ... token_n <eos> <pad> <pad> ... <pad> <pad>]\n",
    "#       -- The first token (<sos>) from the target is removed to create the target_expected_decoder_output.\n",
    "#       -- Used to calculate the loss.\n",
    "#       -- Length: (L - 1)\n",
    "#\n",
    "# The decoder predicts 1 token as output for each token in the input to the decoder. So, the predicted_output \n",
    "# will have 1 more token than the target_expected_decoder_output if we just removed <sos> from target to \n",
    "# create target_expected_decoder_output and use target without changes as input to the decoder. To resolve this \n",
    "# issue, we remove the last token from the target to create target_decoder_input and use it as input to the \n",
    "# decoder. The last token in target is either <eos> or <pad> and it doesn't matter if it is removed. The \n",
    "# predicted_output and target_expected_decoder_output are then compared and used to calculate the loss.\n",
    "#\n",
    "# For now, lets assume that the last token is <eos> and see how the loss is calculated without any problems.\n",
    "#\n",
    "# target_decoder_input = [<sos> token_1 token_2 ... token_n]\n",
    "#       -- <eos> is removed from the end.\n",
    "# target_expected_decoder_output = [token_1 token_2 ... token_n <eos>]\n",
    "#       -- <sos> is removed from the start from the original target but <eos> is not touched.\n",
    "# predicted_output = [output_token_1 output_token_2 ... output_token_n output_token_n+1]\n",
    "#\n",
    "# Now, when calculating the loss target_expected_decoder_output is compared to predicted output. The hope is that\n",
    "# output_token_1 is token_1\n",
    "# output_token_2 is token_2\n",
    "# ...\n",
    "# output_token_n is token_n\n",
    "# output_token_n+1 is <eos>\n",
    "#\n",
    "# Exactly what we want.\n",
    "#\n",
    "# If this explanation is not clear, please refer to the below cells to see the various variables created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2, 10])\n",
      "target_batch: \n",
      " tensor([[   0,   12,    3, 3545,    1,    2,    2,    2,    2,    2],\n",
      "        [   0,  122,    6,  545,   40,   78,   90,   89,   78,    1]],\n",
      "       dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "target_batch = torch.tensor(data=[[sos_token_id, 12, 3, 3545, eos_token_id, pad_token_id, pad_token_id, pad_token_id, pad_token_id, pad_token_id], \n",
    "                                  [sos_token_id, 122, 6, 545, 40, 78, 90, 89, 78, eos_token_id]], dtype=torch.int16)\n",
    "print(\"shape: \", target_batch.shape)\n",
    "print(\"target_batch: \\n\", target_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2, 9])\n",
      "target_decoder_input: \n",
      " tensor([[   0,   12,    3, 3545,    1,    2,    2,    2,    2],\n",
      "        [   0,  122,    6,  545,   40,   78,   90,   89,   78]],\n",
      "       dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "# Remove the last token from the original target sentences to create the target_decoder_input.\n",
    "target_decoder_input = target_batch[:, :-1]\n",
    "print(\"shape: \", target_decoder_input.shape)\n",
    "print(\"target_decoder_input: \\n\", target_decoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2, 9])\n",
      "target_expected_decoder_output: \n",
      " tensor([[  12,    3, 3545,    1,    2,    2,    2,    2,    2],\n",
      "        [ 122,    6,  545,   40,   78,   90,   89,   78,    1]],\n",
      "       dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "# The first token is removed from the original target sequences to create the target_expected_decoder_output.\n",
    "target_expected_decoder_output = target_batch[:, 1:]\n",
    "print(\"shape: \", target_expected_decoder_output.shape)\n",
    "print(\"target_expected_decoder_output: \\n\", target_expected_decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2, 1, 9])\n",
      "target_padding_mask: \n",
      " tensor([[[ True,  True,  True,  True,  True, False, False, False, False]],\n",
      "\n",
      "        [[ True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "shape of target_padding_mask:  torch.Size([2, 9, 9])\n",
      "target_padding_mask: \n",
      " tensor([[[ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False]],\n",
      "\n",
      "        [[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n"
     ]
    }
   ],
   "source": [
    "# We first mask the padding tokens in the target sequences. This is done to prevent the padding tokens\n",
    "# from attending to the other tokens in the target sequences.\n",
    "# Notice that the mask is calculated on the target_decoder_input and not on the target. This is because\n",
    "# the target_decoder_input is used as input to the decoder to predict the next token in the output.\n",
    "target_padding_mask = construct_padding_mask(input=target_decoder_input, pad_token_id=pad_token_id)\n",
    "print(\"shape: \", target_padding_mask.shape)\n",
    "print(\"target_padding_mask: \\n\", target_padding_mask)\n",
    "print(\"-\" * 150)\n",
    "# The target_padding_mask is updated to have the shape [batch_size, L - 1, L - 1] instead of leaving\n",
    "# it as [batch_size, 1, L - 1] like we did with source mask. This is because targets also have look ahead \n",
    "# mask which is different for every single token in the target sequence. So, the look ahead mask below\n",
    "# will have 1 row per token in the sequence and it will be merged with the target_padding_mask to create\n",
    "# the final mask. Hence, we explicitly create the mask for every token in the target sequence before \n",
    "# merging.\n",
    "target_padding_mask = target_padding_mask.repeat(1, target_decoder_input.size(1), 1)\n",
    "print(\"shape of target_padding_mask: \", target_padding_mask.shape)\n",
    "print(\"target_padding_mask: \\n\", target_padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2, 9, 9])\n",
      "target_mask: \n",
      " tensor([[[ True, False, False, False, False, False, False, False, False],\n",
      "         [ True,  True, False, False, False, False, False, False, False],\n",
      "         [ True,  True,  True, False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False]],\n",
      "\n",
      "        [[ True, False, False, False, False, False, False, False, False],\n",
      "         [ True,  True, False, False, False, False, False, False, False],\n",
      "         [ True,  True,  True, False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n"
     ]
    }
   ],
   "source": [
    "# We now create the mask to prevent the future tokens from attending to the current token or any token before it.\n",
    "# We combine both the masks using the logical 'and' operator.\n",
    "# The type_as function is used to ensure that the mask is of the same type as the target_mask. Since, we are using\n",
    "# the logical 'and' operator, the future_mask should be of the same type as the target_mask.\n",
    "# Even though '&' is a bitwise 'and' operator, it is overloaded in PyTorch to work with boolean tensors.\n",
    "# It is the same as applying logical 'and' operator when both the value types being used with '&' are of type \n",
    "# torch.bool. \n",
    "target_mask = target_padding_mask & construct_look_ahead_mask(target_decoder_input.size(-1)).type_as(target_padding_mask.data)\n",
    "print(\"shape: \", target_mask.shape)\n",
    "print(\"target_mask: \\n\", target_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU CAN IGNORE THIS CELL. IT DOESN'T REALLY EFFECT THE MASKS BUT IT IS AN INTERESTING POINT TO \n",
    "# THINK ABOUT. IF THE ARGUMENT BELOW IS NOT CLEAR, JUST IGNORE IT.\n",
    "#\n",
    "# Looking at the target_mask tensor output in the above cell, there is really no value in using the \n",
    "# padding mask in the target sentences. The padding tokens are only at the end of the sentence and \n",
    "# the future tokens are not allowed to attend to the earlier tokens because of the look_ahead_mask \n",
    "# already. This means the padding tokens are already masked for the actual tokens (part of the \n",
    "# sentence) because of the look_ahead_mask. In other words, the padding_mask is not changing \n",
    "# anything in the masks for the rows where the tokens are non-padding tokens. The padding_mask only \n",
    "# changes the target_mask for the rows where the tokens are padding tokens. This anyway doesn't \n",
    "# matter because we don't really use the output of the padding tokens in the final loss calculation.\n",
    "#\n",
    "# However, I don't know why most of the implementations still go ahead and use padding mask in the\n",
    "# target sentences. I am not sure if I am missing something here. So, I am just leaving the code\n",
    "# as it is incase it is important. If you know the reason, please let me know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2, 9])\n",
      "target_decoder_input: \n",
      " tensor([[   0,   12,    3, 3545,    1,    2,    2,    2,    2],\n",
      "        [   0,  122,    6,  545,   40,   78,   90,   89,   78]],\n",
      "       dtype=torch.int16)\n",
      "--------------------------------------------------\n",
      "shape:  torch.Size([2, 1, 9])\n",
      "target_padding_mask_alternative: \n",
      " tensor([[[ True,  True,  True,  True,  True, False, False, False, False]],\n",
      "\n",
      "        [[ True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n",
      "--------------------------------------------------\n",
      "shape:  torch.Size([2, 9, 1])\n",
      "intermediate_padding_mask: \n",
      " tensor([[[ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [False],\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True]]])\n",
      "--------------------------------------------------\n",
      "shape:  torch.Size([2, 9, 9])\n",
      "intermediate_padding_mask: \n",
      " tensor([[[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False]],\n",
      "\n",
      "        [[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n",
      "--------------------------------------------------\n",
      "shape:  torch.Size([2, 9, 9])\n",
      "target_padding_mask_alternative: \n",
      " tensor([[[ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False]],\n",
      "\n",
      "        [[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n"
     ]
    }
   ],
   "source": [
    "# We could mask every single token for the rows that correspond to padding tokens. This is equivalent \n",
    "# to saying that no token can attend to the padding tokens. However, if no token can attend to the \n",
    "# padding token and everything in those rows is set to false, then the attention scores will just \n",
    "# be equal to some constant value (non-negligible). So, in the end, this doesn't really matter and \n",
    "# doesn't give any advantage in computing the attention scores. However, I am showing the \n",
    "# implementation here because this is one more way padding mask is used in some alternative \n",
    "# implementations of the transformer.\n",
    "print(\"shape: \", target_decoder_input.shape)\n",
    "print(\"target_decoder_input: \\n\", target_decoder_input)\n",
    "print(\"--------------------------------------------------\")\n",
    "target_padding_mask_alternative = (target_decoder_input != pad_token_id).unsqueeze(dim=1)\n",
    "print(\"shape: \", target_padding_mask_alternative.shape)\n",
    "print(\"target_padding_mask_alternative: \\n\", target_padding_mask_alternative)\n",
    "print(\"--------------------------------------------------\")\n",
    "# We need to False out the entire rows corresponding to padding tokens. The rows corresponding to the\n",
    "# padding tokens are the rows where the target_padding_mask_alternative is False. So, we transpose the \n",
    "# target_padding_mask_alternative and repeat it 'seq_len' times as a first step.\n",
    "intermediate_padding_mask = target_padding_mask_alternative.transpose(1, 2)\n",
    "print(\"shape: \", intermediate_padding_mask.shape)\n",
    "print(\"intermediate_padding_mask: \\n\", intermediate_padding_mask)\n",
    "print(\"--------------------------------------------------\")\n",
    "# We now repeat the column values 'seq_len' times to match the shape of the target_padding_mask.\n",
    "intermediate_padding_mask = intermediate_padding_mask.repeat(1, 1, target_padding_mask.size(-1))\n",
    "print(\"shape: \", intermediate_padding_mask.shape)\n",
    "print(\"intermediate_padding_mask: \\n\", intermediate_padding_mask)\n",
    "print(\"--------------------------------------------------\")\n",
    "# Finally, we take the logical 'and' of the two intermediate masks to get the final padding mask.\n",
    "target_padding_mask_alternative = intermediate_padding_mask & construct_padding_mask(input=target_decoder_input, pad_token_id=pad_token_id).repeat(1, target_decoder_input.size(1), 1)\n",
    "print(\"shape: \", target_padding_mask_alternative.shape)\n",
    "print(\"target_padding_mask_alternative: \\n\", target_padding_mask_alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We won't be using this function in the transformer implementation since it does not provide any \n",
    "# advantages and it is a waste of computation. This is just to show how the padding mask is created \n",
    "# in some alternative implementations. This function just takes the code from the above cell and \n",
    "# puts it into a single function.\n",
    "def construct_padding_mask_alternative(input: Tensor, pad_token_id: int) -> Tensor:\n",
    "    \"\"\"Creates a padding mask to prevent the padding tokens from attending to the other tokens in\n",
    "       the input. This is the same for both source and target sentences.\n",
    "\n",
    "    Args:\n",
    "        input (Tensor): Input tensor of shape (batch_size, seq_len) where each row is a sentence.\n",
    "        pad_token_id (int): Id of the padding token.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Returns a padding mask of shape (batch_size, seq_len, seq_len) where each 2D tensor\n",
    "        (seq_len, seq_len) is a mask for a single sentence.\n",
    "    \"\"\"\n",
    "    padding_mask = (input != pad_token_id).unsqueeze(dim=1)\n",
    "    intermediate_padding_mask_1 = padding_mask.repeat(1, padding_mask.size(-1), 1)\n",
    "    intermediate_padding_mask_2 = padding_mask.transpose(1, 2)\n",
    "    intermediate_padding_mask_2 = intermediate_padding_mask_2.repeat(1, 1, padding_mask.size(-1))\n",
    "    padding_mask = intermediate_padding_mask_1 & intermediate_padding_mask_2\n",
    "    return padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2, 9, 9])\n",
      "target_padding_mask_alternative_via_function: \n",
      " tensor([[[ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False]],\n",
      "\n",
      "        [[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n"
     ]
    }
   ],
   "source": [
    "target_padding_mask_alternative_via_function = construct_padding_mask_alternative(input=target_decoder_input, pad_token_id=pad_token_id)\n",
    "print(\"shape: \", target_padding_mask_alternative_via_function.shape)\n",
    "print(\"target_padding_mask_alternative_via_function: \\n\", target_padding_mask_alternative_via_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both the alternative target padding masks are equal as they should be.\n"
     ]
    }
   ],
   "source": [
    "if torch.equal(target_padding_mask_alternative, target_padding_mask_alternative_via_function):\n",
    "    print(\"Both the alternative target padding masks are equal as they should be.\")\n",
    "else:\n",
    "    print(\"The alternative target padding masks are not equal. There is some mistake in the code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2, 1, 9, 9])\n",
      "target_mask: \n",
      " tensor([[[[ True, False, False, False, False, False, False, False, False],\n",
      "          [ True,  True, False, False, False, False, False, False, False],\n",
      "          [ True,  True,  True, False, False, False, False, False, False],\n",
      "          [ True,  True,  True,  True, False, False, False, False, False],\n",
      "          [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "          [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "          [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "          [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "          [ True,  True,  True,  True,  True, False, False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True, False, False, False, False, False, False, False, False],\n",
      "          [ True,  True, False, False, False, False, False, False, False],\n",
      "          [ True,  True,  True, False, False, False, False, False, False],\n",
      "          [ True,  True,  True,  True, False, False, False, False, False],\n",
      "          [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "          [ True,  True,  True,  True,  True,  True, False, False, False],\n",
      "          [ True,  True,  True,  True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True,  True,  True,  True,  True, False],\n",
      "          [ True,  True,  True,  True,  True,  True,  True,  True,  True]]]])\n"
     ]
    }
   ],
   "source": [
    "# In the transformers implementation, the same mask is applied to all the heads in the multi-headed\n",
    "# attention mechanism. The calculated attention_scores will have the shape \n",
    "# (batch_size, num_heads, seq_len, seq_len). Hence, the target_mask is updated to have the shape \n",
    "# (batch_size, 1, seq_len, seq_len) which can be broadcasted and applied to all the heads.\n",
    "target_mask = target_mask.unsqueeze(dim=1)\n",
    "print(\"shape: \", target_mask.shape)\n",
    "print(\"target_mask: \\n\", target_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be used in Transformers.\n",
    "class Batch:\n",
    "    \"\"\"Object for holding a batch of data and the corresponding mask to be used for training.\"\"\"\n",
    "\n",
    "    def __init__(self, src_batch: Tensor, tgt_batch: Tensor, pad_token_id: int):\n",
    "        \"\"\"Initialize the Batch object. Updates the tgt_batch to the format expected by the decoder\n",
    "           during training. Also, creates the mask for the source and target sentences.\n",
    "\n",
    "        Args:\n",
    "            src_batch (Tensor): Tensor containing the source sentences in the batch. \n",
    "                                shape: [batch_size, seq_len].\n",
    "            tgt_batch (Tensor): Tensor containing the target sentences in the batch.\n",
    "                                shape: [batch_size, seq_len].\n",
    "            pad_token_id (int): Id of the pad token appended to the sentences in the batch. Usually \n",
    "                                set to 2.\n",
    "        \"\"\"\n",
    "        self.src = src_batch\n",
    "        # The source sentences only need the padding mask since the Encoder does not have to predict\n",
    "        # the next token in the sentence but just encode the input to be used by the Decoder.\n",
    "        # Shape of src_mask: [batch_size, 1, 1, seq_len]\n",
    "        self.src_mask = construct_padding_mask(input=src_batch, pad_token_id=pad_token_id).unsqueeze(1)\n",
    "        # Removes the last token (<eos> or <pad>) from the target sentences to create the target_decoder_input.\n",
    "        # Shape of tgt_decoder_input: [batch_size, seq_len - 1]\n",
    "        self.tgt_decoder_input = tgt_batch[:, :-1]\n",
    "        # Removes the first token (<sos>) from the target sentences to create the target_expected_decoder_output.\n",
    "        # Shape of tgt_expected_decoder_output: [batch_size, seq_len - 1]\n",
    "        self.tgt_expected_decoder_output = tgt_batch[:, 1:]\n",
    "        # Shape of tgt_mask: [batch_size, 1, seq_len - 1, seq_len - 1]\n",
    "        self.tgt_mask = self.construct_target_mask(tgt=self.tgt_decoder_input, pad_token_id=pad_token_id).unsqueeze(1)\n",
    "        # Number of tokens in the target sentences excluding the padding tokens. This is used during model \n",
    "        # training for the loss calculation inorder to normalize the total loss and find the loss per token.\n",
    "        self.non_pad_tokens = (self.tgt_expected_decoder_output != pad_token_id).sum()\n",
    "\n",
    "    def construct_target_mask(self, tgt: Tensor, pad_token_id: int) -> Tensor:\n",
    "        # The target sentences need both the padding mask and the look ahead mask. The padding mask is used\n",
    "        # to prevent the padding tokens from attending to the other tokens in the target sentences. The look\n",
    "        # ahead mask is used to prevent the future tokens from attending to the current token or any token.\n",
    "        tgt_mask = construct_padding_mask(input=tgt, pad_token_id=pad_token_id).repeat(1, tgt.size(1), 1)\n",
    "        tgt_mask = tgt_mask & construct_look_ahead_mask(tgt.size(-1)).type_as(tgt_mask.data)\n",
    "        return tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2, 10])\n",
      "src_batch: \n",
      " tensor([[   24,    42,    33,  4124,   231, 12321,     2,     2,     2,     2],\n",
      "        [   27,    67,    83, 23124,   131,  1321,    23,    90,     2,     2]])\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "shape:  torch.Size([2, 10])\n",
      "target_batch: \n",
      " tensor([[   0,   12,    3, 3545,    1,    2,    2,    2,    2,    2],\n",
      "        [   0,  122,    6,  545,   40,   78,   90,   89,   78,    1]],\n",
      "       dtype=torch.int16)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "shape:  torch.Size([2, 10])\n",
      "src in the batch object: \n",
      " tensor([[   24,    42,    33,  4124,   231, 12321,     2,     2,     2,     2],\n",
      "        [   27,    67,    83, 23124,   131,  1321,    23,    90,     2,     2]])\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "shape:  torch.Size([2, 1, 1, 10])\n",
      "src_mask: \n",
      " tensor([[[[ True,  True,  True,  True,  True,  True, False, False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True,  True,  True,  True,  True,  True, False, False]]]])\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "shape:  torch.Size([2, 9])\n",
      "tgt_decoder_input: \n",
      " tensor([[   0,   12,    3, 3545,    1,    2,    2,    2,    2],\n",
      "        [   0,  122,    6,  545,   40,   78,   90,   89,   78]],\n",
      "       dtype=torch.int16)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "shape:  torch.Size([2, 9])\n",
      "tgt_expected_decoder_output: \n",
      " tensor([[  12,    3, 3545,    1,    2,    2,    2,    2,    2],\n",
      "        [ 122,    6,  545,   40,   78,   90,   89,   78,    1]],\n",
      "       dtype=torch.int16)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "shape:  torch.Size([2, 1, 9, 9])\n",
      "tgt_mask: \n",
      " tensor([[[[ True, False, False, False, False, False, False, False, False],\n",
      "          [ True,  True, False, False, False, False, False, False, False],\n",
      "          [ True,  True,  True, False, False, False, False, False, False],\n",
      "          [ True,  True,  True,  True, False, False, False, False, False],\n",
      "          [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "          [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "          [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "          [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "          [ True,  True,  True,  True,  True, False, False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True, False, False, False, False, False, False, False, False],\n",
      "          [ True,  True, False, False, False, False, False, False, False],\n",
      "          [ True,  True,  True, False, False, False, False, False, False],\n",
      "          [ True,  True,  True,  True, False, False, False, False, False],\n",
      "          [ True,  True,  True,  True,  True, False, False, False, False],\n",
      "          [ True,  True,  True,  True,  True,  True, False, False, False],\n",
      "          [ True,  True,  True,  True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True,  True,  True,  True,  True, False],\n",
      "          [ True,  True,  True,  True,  True,  True,  True,  True,  True]]]])\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of non-padding tokens in the target sentences:  tensor(13)\n"
     ]
    }
   ],
   "source": [
    "batch = Batch(src_batch=src_batch, tgt_batch=target_batch, pad_token_id=pad_token_id)\n",
    "print(\"shape: \", src_batch.shape)\n",
    "print(\"src_batch: \\n\", src_batch)\n",
    "print(\"-\" * 150)\n",
    "print(\"shape: \", target_batch.shape)\n",
    "print(\"target_batch: \\n\", target_batch)\n",
    "print(\"-\" * 150)\n",
    "print(\"shape: \", batch.src.shape)\n",
    "print(\"src in the batch object: \\n\", batch.src)\n",
    "print(\"-\" * 150)\n",
    "print(\"shape: \", batch.src_mask.shape)\n",
    "print(\"src_mask: \\n\", batch.src_mask)\n",
    "print(\"-\" * 150)\n",
    "print(\"shape: \", batch.tgt_decoder_input.shape)\n",
    "print(\"tgt_decoder_input: \\n\", batch.tgt_decoder_input)\n",
    "print(\"-\" * 150)\n",
    "print(\"shape: \", batch.tgt_expected_decoder_output.shape)\n",
    "print(\"tgt_expected_decoder_output: \\n\", batch.tgt_expected_decoder_output)\n",
    "print(\"-\" * 150)\n",
    "print(\"shape: \", batch.tgt_mask.shape)\n",
    "print(\"tgt_mask: \\n\", batch.tgt_mask)\n",
    "print(\"-\" * 150)\n",
    "print(\"Number of non-padding tokens in the target sentences: \", batch.non_pad_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".attention_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
