{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, you learn:\n",
    "#\n",
    "# 1) How to use spacy tokenizers to tokenize text?\n",
    "# 2) How to build vocabulary from a text corpus?\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful resources:\n",
    "#\n",
    "# 1) https://spacy.io/usage/spacy-101\n",
    "#       -- A detailed overview of spacy.\n",
    "# 2) https://spacy.io/usage/models\n",
    "#       -- Explains how to use pretrained spacy tokenizer models.\n",
    "# 3) https://realpython.com/python-for-loop/\n",
    "#       -- To understand iter, iterator and iterables in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "# torchtext is being deprecated, but I am using this for now since it makes it very easy to build the vocab and \n",
    "# use pre-built Spacy tokenizers. In our model, we will use the trained BPETokenizer from Huggingface.\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from typing import Generator, List\n",
    "\n",
    "import datasets\n",
    "import pickle\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI4_BHARAT_DATA_PATH = \"../../Data/AI4Bharat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['idx', 'src', 'tgt'],\n",
      "    num_rows: 4946035\n",
      "})\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "{'idx': 0, 'src': 'Have you heard about Foie gras?', 'tgt': 'ఇక ఫ్రూట్ ఫ్లైస్ గురించి మీరు విన్నారా?'}\n",
      "{'idx': 10000, 'src': 'You eat ants?', 'tgt': 'మీరు చీమలు తినడానికి?'}\n",
      "{'idx': 13234, 'src': 'Thats an interesting one.', 'tgt': 'ఇందులో ఆసక్తికరమైంది ఒకటుంది.'}\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer train dataset which we already saved to the disk in 'step_1_data_exploration.ipynb' notebook.\n",
    "tokenizer_train_dataset = load_from_disk(dataset_path=f\"{AI4_BHARAT_DATA_PATH}/full_en_te_dataset\")\n",
    "print(tokenizer_train_dataset)\n",
    "print(type(tokenizer_train_dataset))\n",
    "print(tokenizer_train_dataset[0])\n",
    "print(tokenizer_train_dataset[10000])\n",
    "print(tokenizer_train_dataset[13234])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Spacy Tokenizer models and tokenizing the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<spacy.tokenizer.Tokenizer object at 0x7f13ffb36710> <class 'spacy.tokenizer.Tokenizer'>\n",
      "<spacy.tokenizer.Tokenizer object at 0x7f140d34cc10> <class 'spacy.tokenizer.Tokenizer'>\n"
     ]
    }
   ],
   "source": [
    "# Load spacy models for English text tokenization.\n",
    "en_model = spacy.load(\"en_core_web_sm\")\n",
    "en_tokenizer = en_model.tokenizer\n",
    "print(en_tokenizer, type(en_tokenizer))\n",
    "# Load spacy model for Telugu text tokenization.\n",
    "te_model = spacy.blank(\"te\")\n",
    "te_tokenizer = te_model.tokenizer\n",
    "print(te_tokenizer, type(te_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english_tokens:  ['Have', 'you', 'heard', 'about', 'Foie', 'gras', '?']\n",
      "telugu_tokens:  ['ఇక', 'ఫ్రూట్', 'ఫ్లైస్', 'గురించి', 'మీరు', 'విన్నారా', '?']\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer the first sentences in the tokenizer train dataset.\n",
    "en_tokens = [token.text for token in en_tokenizer(tokenizer_train_dataset[0][\"src\"])]\n",
    "print(\"english_tokens: \", en_tokens)\n",
    "te_tokens = [token.text for token in te_tokenizer(tokenizer_train_dataset[0][\"tgt\"])]\n",
    "print(\"telugu_tokens: \", te_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(input_text: str, tokenizer: spacy.tokenizer.Tokenizer) -> List[str]:\n",
    "    \"\"\"Tokenizes the input text using the provided tokenizer and returns individual tokens.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): Text to be tokenized.\n",
    "        tokenizer (spacy.tokenizer.Tokenizer): Spacy Tokenizer to tokenize the input text.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing tokens of the input text.\n",
    "    \"\"\"\n",
    "    return [token.text for token in tokenizer(input_text)]\n",
    "\n",
    "def get_text(input: dict, language: str) -> str:\n",
    "    \"\"\"Extracts the text from the input dictionary based on the language provided.\n",
    "\n",
    "    Args:\n",
    "        input (dict): Dictionary corresponding a single translation example containing the text data.\n",
    "        language (str): Language of the text to be extracted.\n",
    "\n",
    "    Returns:\n",
    "        str: Text extracted from the input dictionary based on the language provided.\n",
    "    \"\"\"\n",
    "    if language == \"en\":\n",
    "        return input[\"src\"]\n",
    "    else:\n",
    "        return input[\"tgt\"]\n",
    "\n",
    "# Create a Generator function that yields tokens.\n",
    "# This function returns a generator object which is a type of iterator and can be used to iterate.\n",
    "def yield_tokens(data_iterator: datasets.arrow_dataset.Dataset, tokenizer: spacy.tokenizer.Tokenizer, language: str) -> Generator[List[str], None, None]:\n",
    "    \"\"\"Yields tokens of the corresponding language for each example in the data_iterator.\n",
    "\n",
    "    Args:\n",
    "        data_iterator (datasets.arrow_dataset.Dataset): Input Hugging Face translation dataset shortened for tokenizer training.\n",
    "        tokenizer (spacy.tokenizer.Tokenizer): Spacy tokenizer to tokenize the text.\n",
    "        language (str): language of the text for which the tokens need to be tokenized.\n",
    "\n",
    "    Yields:\n",
    "        Generator[List[str], None, None]: generator that yields tokens of the corresponding language for each example in the data_iterator.\n",
    "    \"\"\"\n",
    "    for en_te_example in data_iterator:\n",
    "        yield tokenize(input_text=get_text(input=en_te_example, language=language), tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English tokens: ['Have', 'you', 'heard', 'about', 'Foie', 'gras', '?']\n",
      "English tokens: ['I', 'never', 'thought', 'of', 'acting', 'in', 'films', '.']\n",
      "\n",
      "\n",
      "Telugu tokens: ['ఇక', 'ఫ్రూట్', 'ఫ్లైస్', 'గురించి', 'మీరు', 'విన్నారా', '?']\n",
      "Telugu tokens: ['సూర్య', 'సినిమాల్లో', 'నటించాలని', 'ఎప్పుడూ', 'అనుకోలేదు', '.']\n"
     ]
    }
   ],
   "source": [
    "# Run this cell just to see how yield_tokens function works.\n",
    "# We need to SKIP THIS CELL while building vocabulary below. If not, we loose the data for the rows already iterated \n",
    "# in this cell.\n",
    "en_token_generator = yield_tokens(data_iterator=tokenizer_train_dataset, tokenizer=en_tokenizer, language=\"en\")\n",
    "print(f\"English tokens: {next(en_token_generator)}\")\n",
    "print(f\"English tokens: {next(en_token_generator)}\\n\\n\")\n",
    "te_token_generator = yield_tokens(data_iterator=tokenizer_train_dataset, tokenizer=te_tokenizer, language=\"te\")\n",
    "print(f\"Telugu tokens: {next(te_token_generator)}\")\n",
    "print(f\"Telugu tokens: {next(te_token_generator)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the vocabulary from the training dataset.\n",
    "# min_freq: Minimum frequency needed for a token to be included in the vocabulary.\n",
    "# max_tokens: Maximum number of tokens to be included in the vocabulary.\n",
    "#       -- Unlike in Byte level BPE, here every other token that is not part of the vocabulary is replaced with <unk>.\n",
    "#       -- So, it is better to keep the vocabulary size as large as possible. However, it is computationally expensive\n",
    "#          since it increases the number of parameters in the embedding layer for the transformer model.\n",
    "# specials: Special tokens to be added in the vocabulary.\n",
    "# special_first: If True, special tokens are added at the beginning of the vocabulary.\n",
    "en_vocab = build_vocab_from_iterator(iterator=yield_tokens(data_iterator=tokenizer_train_dataset, tokenizer=en_tokenizer, language=\"en\"), \n",
    "                                     min_freq=2, \n",
    "                                     max_tokens=None,\n",
    "                                     specials=[\"<sos>\", \"<eos>\", \"<pad>\", \"<unk>\"], \n",
    "                                     special_first=True)\n",
    "te_vocab = build_vocab_from_iterator(iterator=yield_tokens(data_iterator=tokenizer_train_dataset, tokenizer=te_tokenizer, language=\"te\"), \n",
    "                                     min_freq=2,  \n",
    "                                     max_tokens=None,\n",
    "                                     specials=[\"<sos>\", \"<eos>\", \"<pad>\", \"<unk>\"], \n",
    "                                     special_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab() <class 'torchtext.vocab.vocab.Vocab'> 181141\n",
      "Vocab() <class 'torchtext.vocab.vocab.Vocab'> 668560\n"
     ]
    }
   ],
   "source": [
    "# For spacy, if the max_tokens is None, then the vocabulary size is the number of unique tokens in the dataset.\n",
    "# This is around 1,81,141 for English and 6,68,560 for Telugu.\n",
    "print(en_vocab, type(en_vocab), len(en_vocab))\n",
    "print(te_vocab, type(te_vocab), len(te_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "Length of Telugu vocabulary:  30000\n",
      "[('ఇంచార్జ్', 29998), ('ఆహ్వానాలు', 29997), ('ఆర్టీసీకి', 29995), ('అన్\\u200cలిమిటెడ్', 29987), ('అనుసరిస్తున్నారు', 29985)]\n",
      "0 1 2 3\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "<class 'dict'>\n",
      "Length of English vocabulary:  30000\n",
      "[('leveraged', 29998), ('lavender', 29997), ('jubilee', 29993), ('incorporates', 29991), ('hereafter', 29990)]\n",
      "0 1 2 3\n"
     ]
    }
   ],
   "source": [
    "# Explore the built vocabulary.\n",
    "te_vocab_dict = te_vocab.get_stoi()\n",
    "print(type(te_vocab_dict))\n",
    "print(\"Length of Telugu vocabulary: \", len(te_vocab_dict))\n",
    "print(list(te_vocab_dict.items())[:5])\n",
    "print(te_vocab_dict[\"<sos>\"], te_vocab_dict[\"<eos>\"], te_vocab_dict[\"<pad>\"], te_vocab_dict[\"<unk>\"])\n",
    "print(\"-\" * 150)\n",
    "en_vocab_dict = en_vocab.get_stoi()\n",
    "print(type(en_vocab_dict))\n",
    "print(\"Length of English vocabulary: \", len(en_vocab_dict))\n",
    "print(list(en_vocab_dict.items())[:5])\n",
    "print(en_vocab_dict[\"<sos>\"], en_vocab_dict[\"<eos>\"], en_vocab_dict[\"<pad>\"], en_vocab_dict[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Token ప్రతిష్టానం not found and default index is not set\nException raised from __getitem__ at /__w/text/text/pytorch/text/torchtext/csrc/vocab.cpp:43 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f4c1de9e897 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/lib/python3.10/site-packages/torch/lib/libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f4c1de4eb25 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/lib/python3.10/site-packages/torch/lib/libc10.so)\nframe #2: torchtext::Vocab::__getitem__(c10::basic_string_view<char> const&) const + 0x384 (0x7f4b6fd420c4 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/lib/python3.10/site-packages/torchtext/lib/libtorchtext.so)\nframe #3: <unknown function> + 0x1e263 (0x7f4c2a8b5263 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/lib/python3.10/site-packages/torchtext/_torchtext.so)\nframe #4: <unknown function> + 0x3e757 (0x7f4c2a8d5757 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/lib/python3.10/site-packages/torchtext/_torchtext.so)\nframe #5: <unknown function> + 0x15cb2e (0x564d080f2b2e in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #6: _PyObject_MakeTpCall + 0x25b (0x564d080e92db in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #7: <unknown function> + 0x16b55b (0x564d0810155b in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #8: <unknown function> + 0x1c57e1 (0x564d0815b7e1 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #9: <unknown function> + 0x1c52be (0x564d0815b2be in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #10: _PyEval_EvalFrameDefault + 0xbfd (0x564d080dbe0d in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #11: <unknown function> + 0x1c548e (0x564d0815b48e in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #12: <unknown function> + 0x1c52be (0x564d0815b2be in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #13: _PyEval_EvalFrameDefault + 0xbfd (0x564d080dbe0d in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #14: <unknown function> + 0x142016 (0x564d080d8016 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #15: PyEval_EvalCode + 0x86 (0x564d081cd8b6 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #16: <unknown function> + 0x23d5fd (0x564d081d35fd in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #17: <unknown function> + 0x15d689 (0x564d080f3689 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #18: _PyEval_EvalFrameDefault + 0x6bc (0x564d080db8cc in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #19: <unknown function> + 0x17a8b0 (0x564d081108b0 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #20: _PyEval_EvalFrameDefault + 0x26f4 (0x564d080dd904 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #21: <unknown function> + 0x17a8b0 (0x564d081108b0 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #22: _PyEval_EvalFrameDefault + 0x26f4 (0x564d080dd904 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #23: <unknown function> + 0x17a8b0 (0x564d081108b0 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #24: <unknown function> + 0x257fef (0x564d081edfef in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #25: <unknown function> + 0x168d1a (0x564d080fed1a in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #26: _PyEval_EvalFrameDefault + 0x8ab (0x564d080dbabb in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #27: _PyFunction_Vectorcall + 0x7c (0x564d080f342c in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #28: _PyEval_EvalFrameDefault + 0x6bc (0x564d080db8cc in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #29: _PyFunction_Vectorcall + 0x7c (0x564d080f342c in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #30: _PyEval_EvalFrameDefault + 0x8ab (0x564d080dbabb in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #31: <unknown function> + 0x16b281 (0x564d08101281 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #32: PyObject_Call + 0x122 (0x564d08101f22 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #33: _PyEval_EvalFrameDefault + 0x285e (0x564d080dda6e in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #34: <unknown function> + 0x16b281 (0x564d08101281 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #35: _PyEval_EvalFrameDefault + 0x1983 (0x564d080dcb93 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #36: <unknown function> + 0x17a8b0 (0x564d081108b0 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #37: _PyEval_EvalFrameDefault + 0x26f4 (0x564d080dd904 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #38: <unknown function> + 0x17a8b0 (0x564d081108b0 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #39: _PyEval_EvalFrameDefault + 0x26f4 (0x564d080dd904 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #40: <unknown function> + 0x17a8b0 (0x564d081108b0 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #41: _PyEval_EvalFrameDefault + 0x26f4 (0x564d080dd904 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #42: <unknown function> + 0x17a8b0 (0x564d081108b0 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #43: _PyEval_EvalFrameDefault + 0x26f4 (0x564d080dd904 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #44: <unknown function> + 0x17a8b0 (0x564d081108b0 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #45: _PyEval_EvalFrameDefault + 0x26f4 (0x564d080dd904 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #46: <unknown function> + 0x17a8b0 (0x564d081108b0 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #47: <unknown function> + 0x928e (0x7f4c8a4ba28e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)\nframe #48: <unknown function> + 0xa49b (0x7f4c8a4bb49b in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)\nframe #49: <unknown function> + 0x15c574 (0x564d080f2574 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #50: <unknown function> + 0x239505 (0x564d081cf505 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #51: <unknown function> + 0x2b5e82 (0x564d0824be82 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #52: <unknown function> + 0x15020b (0x564d080e620b in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #53: _PyEval_EvalFrameDefault + 0x285e (0x564d080dda6e in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #54: _PyFunction_Vectorcall + 0x7c (0x564d080f342c in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #55: _PyEval_EvalFrameDefault + 0x8ab (0x564d080dbabb in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #56: _PyFunction_Vectorcall + 0x7c (0x564d080f342c in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #57: _PyEval_EvalFrameDefault + 0x8ab (0x564d080dbabb in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #58: _PyFunction_Vectorcall + 0x7c (0x564d080f342c in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #59: _PyEval_EvalFrameDefault + 0x8ab (0x564d080dbabb in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #60: _PyFunction_Vectorcall + 0x7c (0x564d080f342c in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #61: _PyEval_EvalFrameDefault + 0x8ab (0x564d080dbabb in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #62: _PyFunction_Vectorcall + 0x7c (0x564d080f342c in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #63: _PyEval_EvalFrameDefault + 0x8ab (0x564d080dbabb in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Apparently, this word is not part of the vocabulary and is raising an error.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mte_vocab\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mప్రతిష్టానం\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m~/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/lib/python3.10/site-packages/torchtext/vocab/vocab.py:65\u001b[0m, in \u001b[0;36mVocab.__getitem__\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mexport\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, token: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m        token: The token used to lookup the corresponding index.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m        The index corresponding to the associated token.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Token ప్రతిష్టానం not found and default index is not set\nException raised from __getitem__ at /__w/text/text/pytorch/text/torchtext/csrc/vocab.cpp:43 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f4c1de9e897 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/lib/python3.10/site-packages/torch/lib/libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f4c1de4eb25 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/lib/python3.10/site-packages/torch/lib/libc10.so)\nframe #2: torchtext::Vocab::__getitem__(c10::basic_string_view<char> const&) const + 0x384 (0x7f4b6fd420c4 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/lib/python3.10/site-packages/torchtext/lib/libtorchtext.so)\nframe #3: <unknown function> + 0x1e263 (0x7f4c2a8b5263 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/lib/python3.10/site-packages/torchtext/_torchtext.so)\nframe #4: <unknown function> + 0x3e757 (0x7f4c2a8d5757 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/lib/python3.10/site-packages/torchtext/_torchtext.so)\nframe #5: <unknown function> + 0x15cb2e (0x564d080f2b2e in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #6: _PyObject_MakeTpCall + 0x25b (0x564d080e92db in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #7: <unknown function> + 0x16b55b (0x564d0810155b in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #8: <unknown function> + 0x1c57e1 (0x564d0815b7e1 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #9: <unknown function> + 0x1c52be (0x564d0815b2be in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #10: _PyEval_EvalFrameDefault + 0xbfd (0x564d080dbe0d in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #11: <unknown function> + 0x1c548e (0x564d0815b48e in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #12: <unknown function> + 0x1c52be (0x564d0815b2be in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #13: _PyEval_EvalFrameDefault + 0xbfd (0x564d080dbe0d in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #14: <unknown function> + 0x142016 (0x564d080d8016 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #15: PyEval_EvalCode + 0x86 (0x564d081cd8b6 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #16: <unknown function> + 0x23d5fd (0x564d081d35fd in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #17: <unknown function> + 0x15d689 (0x564d080f3689 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #18: _PyEval_EvalFrameDefault + 0x6bc (0x564d080db8cc in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #19: <unknown function> + 0x17a8b0 (0x564d081108b0 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #20: _PyEval_EvalFrameDefault + 0x26f4 (0x564d080dd904 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #21: <unknown function> + 0x17a8b0 (0x564d081108b0 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #22: _PyEval_EvalFrameDefault + 0x26f4 (0x564d080dd904 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #23: <unknown function> + 0x17a8b0 (0x564d081108b0 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #24: <unknown function> + 0x257fef (0x564d081edfef in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #25: <unknown function> + 0x168d1a (0x564d080fed1a in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #26: _PyEval_EvalFrameDefault + 0x8ab (0x564d080dbabb in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #27: _PyFunction_Vectorcall + 0x7c (0x564d080f342c in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #28: _PyEval_EvalFrameDefault + 0x6bc (0x564d080db8cc in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #29: _PyFunction_Vectorcall + 0x7c (0x564d080f342c in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #30: _PyEval_EvalFrameDefault + 0x8ab (0x564d080dbabb in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #31: <unknown function> + 0x16b281 (0x564d08101281 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #32: PyObject_Call + 0x122 (0x564d08101f22 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #33: _PyEval_EvalFrameDefault + 0x285e (0x564d080dda6e in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #34: <unknown function> + 0x16b281 (0x564d08101281 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #35: _PyEval_EvalFrameDefault + 0x1983 (0x564d080dcb93 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #36: <unknown function> + 0x17a8b0 (0x564d081108b0 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #37: _PyEval_EvalFrameDefault + 0x26f4 (0x564d080dd904 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #38: <unknown function> + 0x17a8b0 (0x564d081108b0 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #39: _PyEval_EvalFrameDefault + 0x26f4 (0x564d080dd904 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #40: <unknown function> + 0x17a8b0 (0x564d081108b0 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #41: _PyEval_EvalFrameDefault + 0x26f4 (0x564d080dd904 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #42: <unknown function> + 0x17a8b0 (0x564d081108b0 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #43: _PyEval_EvalFrameDefault + 0x26f4 (0x564d080dd904 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #44: <unknown function> + 0x17a8b0 (0x564d081108b0 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #45: _PyEval_EvalFrameDefault + 0x26f4 (0x564d080dd904 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #46: <unknown function> + 0x17a8b0 (0x564d081108b0 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #47: <unknown function> + 0x928e (0x7f4c8a4ba28e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)\nframe #48: <unknown function> + 0xa49b (0x7f4c8a4bb49b in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)\nframe #49: <unknown function> + 0x15c574 (0x564d080f2574 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #50: <unknown function> + 0x239505 (0x564d081cf505 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #51: <unknown function> + 0x2b5e82 (0x564d0824be82 in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #52: <unknown function> + 0x15020b (0x564d080e620b in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #53: _PyEval_EvalFrameDefault + 0x285e (0x564d080dda6e in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #54: _PyFunction_Vectorcall + 0x7c (0x564d080f342c in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #55: _PyEval_EvalFrameDefault + 0x8ab (0x564d080dbabb in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #56: _PyFunction_Vectorcall + 0x7c (0x564d080f342c in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #57: _PyEval_EvalFrameDefault + 0x8ab (0x564d080dbabb in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #58: _PyFunction_Vectorcall + 0x7c (0x564d080f342c in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #59: _PyEval_EvalFrameDefault + 0x8ab (0x564d080dbabb in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #60: _PyFunction_Vectorcall + 0x7c (0x564d080f342c in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #61: _PyEval_EvalFrameDefault + 0x8ab (0x564d080dbabb in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #62: _PyFunction_Vectorcall + 0x7c (0x564d080f342c in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\nframe #63: _PyEval_EvalFrameDefault + 0x8ab (0x564d080dbabb in /home/maneesh/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/bin/python)\n"
     ]
    }
   ],
   "source": [
    "# Apparently, this word is not part of the vocabulary and is raising an error.\n",
    "print(te_vocab[\"ప్రతిష్టానం\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are the setting the default index to the index associated with '<unk>' token.\n",
    "# This makes sure that we get the index corresponding to '<unk>' if some text that is not present in the vocabulary is queried.\n",
    "te_vocab.set_default_index(te_vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[3, 3, 20789]\n"
     ]
    }
   ],
   "source": [
    "# It rightly prints '3' which is the index corresponding to the token '<unk>'.\n",
    "print(te_vocab([\"ప్రతిష్టానం\"]))\n",
    "# Notice that we can pass a list of tokens to get the corresponding indices all at once.\n",
    "print(te_vocab([\"ప్రతిష్టానం\", \"హోషంగాబాద్\", \"హోల్డర్\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', 'నలుగురు', 'పోతుంది']\n",
      "['<unk>', 'suicide', '87']\n"
     ]
    }
   ],
   "source": [
    "# Moving from index to tokens.\n",
    "print(te_vocab.lookup_tokens([3, 545, 6767]))\n",
    "print(en_vocab.lookup_tokens([3, 545, 6767]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Vocab' object has no attribute 'to_disk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43men_vocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_disk\u001b[49m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAI4_BHARAT_DATA_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/trained_models/tokenizers/spacy/en_vocab\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Learning/AI/GenAI/Projects/attention_is_all_you_need/.attention_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Vocab' object has no attribute 'to_disk'"
     ]
    }
   ],
   "source": [
    "# Lets try to save the vocabulary to the disk in a pickle file.\n",
    "EN_VOCAB_FILEPATH = f\"{AI4_BHARAT_DATA_PATH}/trained_models/tokenizers/spacy/en_vocab.pkl\"\n",
    "file_obj = open(EN_VOCAB_FILEPATH, 'wb')\n",
    "pickle.dump(en_vocab, file_obj)\n",
    "file_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".attention_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
