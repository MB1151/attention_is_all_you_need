{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, you learn:\n",
    "#\n",
    "# 1) How to use DataLoader in Pytorch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources to go through before continuing further in this notebook:\n",
    "#\n",
    "# 1) https://machinelearningmastery.com/training-a-pytorch-model-with-dataloader-and-dataset/\n",
    "#       -- Explain how to use Dataset and DataLoader in pytorch.\n",
    "# 2) https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel\n",
    "#       -- Explain how to use Dataset and DataLoader in pytorch.\n",
    "# 3) https://blog.paperspace.com/dataloaders-abstractions-pytorch/\n",
    "#       -- Explains how to use Dataset and DataLoader in pytorch.\n",
    "# 4) https://pytorch.org/docs/stable/data.html\n",
    "#       -- Official pytorch documentation for DataLoader interface.\n",
    "# 5) https://geekflare.com/python-unpacking-operators/\n",
    "#       -- Explains unpacking operators(*, **) in python.\n",
    "# 6) https://realpython.com/python-zip-function/\n",
    "#       -- zip function in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'zip'> <zip object at 0x7fef43a6dd00>\n",
      "[(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "<class 'zip'> <zip object at 0x7fef43a6ec80>\n",
      "[(1, 'a', 'A'), (2, 'b', 'B'), (3, 'c', 'C'), (4, 'd', 'D')]\n"
     ]
    }
   ],
   "source": [
    "# Example to show the usage of zip in python\n",
    "sample_iterable_1 = [1, 2, 3, 4]\n",
    "sample_iterable_2 = ['a', 'b', 'c', 'd']\n",
    "# zip combines the corresponding elements of each iterable into a tuple.\n",
    "zip_output_1 = zip(sample_iterable_1, sample_iterable_2)\n",
    "print(type(zip_output_1), zip_output_1)\n",
    "print(list(zip_output_1))\n",
    "print(\"-\" * 150)\n",
    "# The last element 'E' will be ignored since the shortest iterable among the passed ones has size '4'.\n",
    "sample_iterable_3 = ['A', 'B', 'C', 'D', 'E']\n",
    "zip_output_2 = zip(sample_iterable_1, sample_iterable_2, sample_iterable_3)\n",
    "print(type(zip_output_2), zip_output_2)\n",
    "print(list(zip_output_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n",
      "(1, 2) (3, 4) (5, 6) (7, 8)\n"
     ]
    }
   ],
   "source": [
    "# Example to show the usage of unpacking operator (*).\n",
    "# * just unpacks the iterables and gives out individual elements.\n",
    "sample_iterable_1 = [1, 2, 3]\n",
    "print(*sample_iterable_1)\n",
    "sample_iterable2 = [(1, 2), (3, 4), (5, 6), (7, 8)]\n",
    "print(*sample_iterable2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a SimpleDataset to be used in assocation with pytorch 'DataLoader'.\n",
    "# This is a pytorch 'Dataset' class which needs to be inherited to create a custom dataset.\n",
    "# 'DataLoader' uses 'Dataset' type to iterate on the data.\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, data: List[Tuple[int, int]]):\n",
    "        # We are just using a random list of tuples for the data to show the usage of Dataset and DataLoader.\n",
    "        self.data = data\n",
    "\n",
    "    # This function needs to be implemented for DataLoader to work with Dataset.\n",
    "    # It needs to return the length of the dataset which will be used to create \n",
    "    # batches by the DataLoader.\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    # This function needs to be implemented for DataLoader to work with Dataset.\n",
    "    # Given an index, it needs to return the datapoint at that index.\n",
    "    def __getitem__(self, index: int) -> Tuple[int, int]:\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a very simple custom collate_fn that gets a batch of input tuples (features, target)\n",
    "# and combines them into a batched tensor format which is the input format expected by our\n",
    "# transformer model.\n",
    "def custom_collate_fn(batch: List[Tuple[int, int]]) -> Tuple[Tensor, Tensor]:\n",
    "    # batch is a list of (feature, target) pairs. This is what collate_fn\n",
    "    # is passed in the DataLoader by default.\n",
    "    print(f\"In custom_collate_fn:batch: {batch}, -- type(batch): {type(batch)}\")\n",
    "    # Refer the above 2 cells to understand this operation.\n",
    "    # [(0, 1), (1, 2), (2, 3), (3, 4)] --> (0, 1), (1, 2), (2, 3), (3, 4) --> *batch does this where each tuple produced is an iterable.\n",
    "    # (0, 1), (1, 2), (2, 3), (3, 4) --> [(0, 1, 2, 3), (1, 2, 3, 4)] --> zip(*batch) does this where corresponding elements at every index are added to a tuple.\n",
    "    # features = (0, 1, 2, 3) and labels = (1, 2, 3, 4)\n",
    "    features, labels = zip(*batch)\n",
    "    print(f\"In custom_collate_fn:features: {features}, -- type(features): {type(features)}\")\n",
    "    print(f\"In custom_collate_fn:labels: {labels}, -- type(labels): {type(labels)}\")\n",
    "    # Convert the features tuple into a tensor which is what the transformer expects.\n",
    "    features = torch.tensor(features, dtype=torch.float32)\n",
    "    print(f\"In custom_collate_fn:features: {features}\")\n",
    "    # Convert the labels tuple into a tensor which is what the transformer expects.\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    print(f\"In custom_collate_fn:labels: {labels}\")\n",
    "    return features, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12)]\n",
      "<class '__main__.SimpleDataset'>  --  <__main__.SimpleDataset object at 0x7fef43a53be0>\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset object which is passed to the DataLoader.\n",
    "data = [(i, i + 1) for i in range(12)]\n",
    "print(f\"data: {data}\")\n",
    "# Notice that the HuggingFace's 'datasets.arrow_dataset.Dataset' which we used step 1 and step 2 notebooks is not the same as \n",
    "# the pytorch's 'torch.utils.data.Dataset'.\n",
    "my_dataset = SimpleDataset(data=data)\n",
    "print(type(my_dataset), \" -- \", my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'DataLoader' object by passing the pytorch 'Dataset' (my_dataset) object created above.\n",
    "# 'num_workers' specifies the number of workers to be used to load the data. Increase the number of workers\n",
    "# to load the data faster.\n",
    "my_dataloader = DataLoader(dataset=my_dataset, num_workers=0, batch_size=4, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>  --  <torch.utils.data.dataloader.DataLoader object at 0x7fef43a52980>\n"
     ]
    }
   ],
   "source": [
    "print(type(my_dataloader), \" -- \", my_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THERE IS SOME WEIRD ISSUE WITH PARALLEL PROCESSING OF DATA ON WINDOWS AND MAC WHICH LEADS TO THE ERROR IN THE NEXT CELL. PYTORCH OFFICIAL [DOCUMENTATION](https://pytorch.org/docs/stable/data.html#multi-process-data-loading) GIVES MORE DETAILS ABOUT THIS ISSUE (THOUGH NOT FULLY CLEAR) AND HOW TO AVOID THIS ERROR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I faced the error as described in this blog (https://discuss.pytorch.org/t/errors-when-using-num-workers-0-in-dataloader/97564) \n",
    "# when I first tried num_workers >= 1 while creating the DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In custom_collate_fn:batch: [(0, 1), (1, 2), (2, 3), (3, 4)], -- type(batch): <class 'list'>\n",
      "In custom_collate_fn:features: (0, 1, 2, 3), -- type(features): <class 'tuple'>\n",
      "In custom_collate_fn:labels: (1, 2, 3, 4), -- type(labels): <class 'tuple'>\n",
      "In custom_collate_fn:features: tensor([0., 1., 2., 3.])\n",
      "In custom_collate_fn:labels: tensor([1., 2., 3., 4.])\n",
      "features: tensor([0., 1., 2., 3.]), -- type(features): <class 'torch.Tensor'>\n",
      "labels: tensor([1., 2., 3., 4.]), -- type(labels): <class 'torch.Tensor'>\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "In custom_collate_fn:batch: [(4, 5), (5, 6), (6, 7), (7, 8)], -- type(batch): <class 'list'>\n",
      "In custom_collate_fn:features: (4, 5, 6, 7), -- type(features): <class 'tuple'>\n",
      "In custom_collate_fn:labels: (5, 6, 7, 8), -- type(labels): <class 'tuple'>\n",
      "In custom_collate_fn:features: tensor([4., 5., 6., 7.])\n",
      "In custom_collate_fn:labels: tensor([5., 6., 7., 8.])\n",
      "features: tensor([4., 5., 6., 7.]), -- type(features): <class 'torch.Tensor'>\n",
      "labels: tensor([5., 6., 7., 8.]), -- type(labels): <class 'torch.Tensor'>\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "In custom_collate_fn:batch: [(8, 9), (9, 10), (10, 11), (11, 12)], -- type(batch): <class 'list'>\n",
      "In custom_collate_fn:features: (8, 9, 10, 11), -- type(features): <class 'tuple'>\n",
      "In custom_collate_fn:labels: (9, 10, 11, 12), -- type(labels): <class 'tuple'>\n",
      "In custom_collate_fn:features: tensor([ 8.,  9., 10., 11.])\n",
      "In custom_collate_fn:labels: tensor([ 9., 10., 11., 12.])\n",
      "features: tensor([ 8.,  9., 10., 11.]), -- type(features): <class 'torch.Tensor'>\n",
      "labels: tensor([ 9., 10., 11., 12.]), -- type(labels): <class 'torch.Tensor'>\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# NOTE: This cell will work fine (without any errors on Windows, Mac) if the 'num_workers' is set \n",
    "# to '0' but fails if num_workers is set to a number >=1 . It works fine on Linux even with num_workers >= 1.\n",
    "# Observe that each batch is being passed through the custom collate function to create a single tensor for \n",
    "# features and labels. The print statements in the custom_collate_fn will help you understand the flow of data.\n",
    "# However, the prints will all be jumbled up if num_workers is set to a number >= 1 since processing is done in \n",
    "# parallel.\n",
    "# Use the 'DataLoader' object to iterate through the 'Dataset' in batches.\n",
    "for features, labels in my_dataloader:\n",
    "    print(f\"features: {features}, -- type(features): {type(features)}\")\n",
    "    print(f\"labels: {labels}, -- type(labels): {type(labels)}\")\n",
    "    print(\"-\" * 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".attention_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
